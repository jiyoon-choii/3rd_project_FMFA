{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 데이터프레임 이름은 to_nnp_tripadvisor 1,2,3.... 형태로 해주세욥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 열기 및 변수 지정 \n",
    "with open('./data/#파일이름#','rb') as fw :\n",
    "    data = pickle.load(fw)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 별로 리스트로 만들어주기 \n",
    "cls_attr = list()\n",
    "res_name = list()\n",
    "food_name = list()\n",
    "user_name = list()\n",
    "rev_title = list()\n",
    "review = list()\n",
    "\n",
    "for i in range(len('''파일 이름''')) :\n",
    "    try :\n",
    "        value_list = list(dict('''파일 이름'''[i]).values())  \n",
    "        cls_attr.append(value_list[0])\n",
    "        res_name.append(value_list[1])\n",
    "        food_name.append(value_list[2])\n",
    "        \n",
    "        review.append(value_list[5].lower())  \n",
    "    except : \n",
    "        continue   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len 확인하여 모두 같으면 데이터프레임 만들 수 있음 \n",
    "len(cls_attr), len(res_name), len(food_name), len(user_name), len(rev_title), len(review) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 만들기 \n",
    "'''변수명''' = pd.DataFrame({'cls_attr' : cls_attr, 'res_name' : res_name, 'food_name' : food_name, 'user_name' : user_name, 'rev_title' : rev_title, 'review' : review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임에서 food_name 컬럼 중복값 제거하여 컬럼 종류 보기 \n",
    "# 볼 컬럼 : res_name 이 한글인 것 \n",
    "# 혹은 food_name이 한국,한국에서 파는음식 에 어떤 게 있는지 (그것만 거를 거임)\n",
    "'''변수명'''.drop_duplicates(['''중복 제거할 컬럼'''], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review 컬럼을 review_sentence 리스트로 받기 \n",
    "review_sentence = list()\n",
    "for i in review :\n",
    "    review_sentence.append(i.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_sentence 속 문장들을 어절 단위로 나누어\n",
    "# 어절 중 stop_word 를 뺀 문장들을 nnp_sentence 리스트에 넣기 \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "nnp_sentence = []\n",
    "for w in review_sentence: \n",
    "    for i in range(len(review_sentence)) :\n",
    "        for token in review_sentence[i] :\n",
    "            tokens = word_tokenize(token)\n",
    "            if token not in stop_words: \n",
    "                nnp_sentence.append(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review 속 문장들에서 영어인 것만 추출하여\n",
    "# pos_tag 함수를 통해 어절 단위로 나눈 후 [(단어),(단어 형태소)] 형태로 \n",
    "# nnp_word 리스트에 추가 \n",
    "import re\n",
    "nnp_word = list()\n",
    "for i in review :\n",
    "    p = re.compile('[a-z]+')\n",
    "    words = p.findall(i)\n",
    "    data_pos = nltk.pos_tag(words) \n",
    "    nnp_word.append(data_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 / 단어 형태소 나누어 각 리스트로 받기 \n",
    "word = list()\n",
    "word_nnp = list()\n",
    "\n",
    "for i in range(len(nnp_list)) :\n",
    "    for k in range(len(nnp_list[i])) :\n",
    "        word.append(nnp_list[i][k][0])\n",
    "        word_nnp.append(nnp_list[i][k][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떤 형태소 있는지 보기 \n",
    "nnp_listup['nnp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
