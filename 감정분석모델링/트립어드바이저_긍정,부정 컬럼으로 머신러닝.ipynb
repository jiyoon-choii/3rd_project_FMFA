{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목표 : 머신러닝 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 분류한 리뷰로 머신러닝 돌리기 => 정확도 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_1 = pd.read_csv(\"./data/sentiment_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_1 = sentiment_1.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>P/N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We’d never had Korean before and I’d been want...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really was unsure of how much of the menu wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolutely delicious authentic Korean food ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  P/N\n",
       "0  We’d never had Korean before and I’d been want...    1\n",
       "1  I really was unsure of how much of the menu wo...    1\n",
       "2  Absolutely delicious authentic Korean food ser...    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# 전처리 작업을 위해 호출될 함수\n",
    "def preprocessor(text) :\n",
    "    # 문자열의 내의 html 태그를 삭제한다.\n",
    "    # 문자열에서 이모티콘을 찾아낸다.\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)|\\^.?\\^', str(text))\n",
    "    # 문장에서 특수문자를 제거하고\n",
    "    # 문자열을 소문자로 변하고\n",
    "    # 추출한 이모티콘을 붙혀준다.\n",
    "    text = re.sub('[\\W]+', ' ', str(text).lower() + ' '.join(emoticons).replace('-', ''))\n",
    "    # print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiment_1[\"review\"] = sentiment_1[\"review\"].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_1.to_csv(\"./data/refined_review.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>P/N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we d never had korean before and i d been want...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i really was unsure of how much of the menu wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely delicious authentic korean food ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the banchan or side dishes that they serve are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my eleven year old twins beg to get biminbop o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  P/N\n",
       "0  we d never had korean before and i d been want...    1\n",
       "1  i really was unsure of how much of the menu wo...    1\n",
       "2  absolutely delicious authentic korean food ser...    1\n",
       "3  the banchan or side dishes that they serve are...    1\n",
       "4  my eleven year old twins beg to get biminbop o...    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_review = pd.read_csv(\"./data/refined_review.csv\")\n",
    "refined_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step2_preprocessing() :\n",
    "#     # csv 데이터를 읽어온다.\n",
    "#     df = pd.read_csv('./data/trip_final.csv')\n",
    "\n",
    "#     # 전처리 작업\n",
    "#     stime = time()\n",
    "#     print('전처리 시작')\n",
    "#     df[\"review\"] = df['review'].apply(preprocessor)\n",
    "#     print('전처리 완료')\n",
    "#     print('소요시간 : %d' % (time() - stime))\n",
    "\n",
    "#     # 전처리된 데이터를 저장한다.\n",
    "#     df.to_csv('./data/pre_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평점 전처리\n",
    "def star_proprocessing(text) :\n",
    "    value = int(text)\n",
    "    if value <= 3.0 :\n",
    "        return '0'\n",
    "    else :\n",
    "        return '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2_preprocessing():\n",
    "    # 수집한 데이터를 읽어온다.\n",
    "    df = pd.read_csv('./data/trip_final.csv')\n",
    "    # print(df)\n",
    "\n",
    "    # 전처리 과정\n",
    "    df['rating'] = df['rating'].apply(star_proprocessing)\n",
    "    # 학습 데이터와 테스트 데이터로 나눈다.\n",
    "    text_list = df['review'].tolist()\n",
    "    star_list = df['rating'].tolist()\n",
    "\n",
    "    text_train, text_test, star_train, star_test = train_test_split(text_list, star_list, test_size=0.3, random_state=0)\n",
    "    #print(len(text_train))\n",
    "    #print(len(text_test))\n",
    "    #print(len(star_train))\n",
    "    #print(len(star_test))\n",
    "\n",
    "    # 저장한다.\n",
    "    dic_train = {\n",
    "        'text' : text_train,\n",
    "        'star' : star_train\n",
    "    }\n",
    "    df_tran = pd.DataFrame(dic_train)\n",
    "\n",
    "    dic_test = {\n",
    "        'text' : text_test,\n",
    "        'star' : star_test\n",
    "    }\n",
    "    df_test = pd.DataFrame(dic_test)\n",
    "\n",
    "    df_tran.to_csv('./data/trip_train_data.csv', index=False)\n",
    "    df_test.to_csv('./data/trip_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# step3_word_tokenizer.py\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# stopword 단어 사전을 다운로드 받는다.\n",
    "nltk.download('stopwords')\n",
    "# stopword 데이터를 가져온다.\n",
    "stop = stopwords.words('english')\n",
    "# 단어 줄기를 하기위한 객체\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백으로 단어분리\n",
    "def tokenizer(text) :\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어줄기\n",
    "def tokenizer_porter(text) :\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_stopwordsr(text) :\n",
    "    # 띄어쓰기를 기준으로 분리한다.\n",
    "    word_list = text.split()\n",
    "    #단어 줄기 처리\n",
    "    word_list2 = \\\n",
    "        [porter.stem(word) for word in word_list]\n",
    "    #불용어 처리\n",
    "    result = []\n",
    "    for w in word_list2: \n",
    "        if w not in stop: \n",
    "            result.append(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3_word_tokenizer() :\n",
    "    text = 'runners like running and thus they run'\n",
    "\n",
    "    a1 = tokenizer(text)\n",
    "    a2 = tokenizer_porter(text)\n",
    "    print('a1 :', a1)\n",
    "    print('a2 :', a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_learning() :\n",
    "    # csv 파일에서 데이터를 읽어온다.\n",
    "    df = pd.read_csv('./data/refined_review.csv')\n",
    "    # 테스트, 학습데이터로 나눈다.\n",
    "    X_train = df.loc[:700 - 1, 'review'].values\n",
    "    y_train = df.loc[:700 - 1, 'P/N'].values\n",
    "\n",
    "    X_test = df.loc[300:, 'review'].values\n",
    "    y_test = df.loc[300:, 'P/N'].values\n",
    "\n",
    "    # 단어장을 만들어주는 객체 생성\n",
    "    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "    # tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer_stopwordsr)\n",
    "    # 데이터를 학습하기 위한 객체\n",
    "    logistic = LogisticRegression(C=10.0, penalty='l2', random_state=0)\n",
    "    # 파이프 라인 설정\n",
    "    pipeline = Pipeline([('vect', tfidf), ('clf', logistic)])\n",
    "\n",
    "    # 학습한다.\n",
    "    stime = time()\n",
    "    print('학습 시작')\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print('학습 종료')\n",
    "    print('총 학습시간 : %d' % (time() - stime))\n",
    "\n",
    "    # 테스트\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"정확도 : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # 성능 확인\n",
    "    y_true = y_test\n",
    "    y_hat = y_pred\n",
    "    print(\"R2 score : \", r2_score(y_true, y_hat))\n",
    "    print(\"mean_absolute_error : \", mean_absolute_error(y_true, y_hat))\n",
    "    print(\"mean_squared_error : \", mean_squared_error(y_true, y_hat))\n",
    "\n",
    "    # 학습이 완료된 객체를 저장한다.\n",
    "    with open('./data/trip.dat', 'wb') as fp :\n",
    "        pickle.dump(pipeline, fp)\n",
    "\n",
    "    print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n",
      "학습 종료\n",
      "총 학습시간 : 0\n",
      "정확도 : 0.951\n",
      "R2 score :  0.4861405405405407\n",
      "mean_absolute_error :  0.04864091559370529\n",
      "mean_squared_error :  0.04864091559370529\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "step4_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 별점으로 긍정부정 머신러닝 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_2 = pd.read_csv(\"./data/sentiment_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_2 = sentiment_2.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_2[\"review\"] = sentiment_2[\"review\"].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_2.to_csv(\"./data/refined_review_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "refined_review_2 = refined_review_2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_review_2.to_csv(\"./data/refined_review_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refined_review_2 = pd.read_csv(\"./data/refined_review_2.csv\")\n",
    "refined_review_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refined_review_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_review_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_learning() :\n",
    "    # csv 파일에서 데이터를 읽어온다.\n",
    "    df = pd.read_csv('./data/refined_review_2.csv')\n",
    "    # 테스트, 학습데이터로 나눈다.\n",
    "    X_train = df.loc[:35000, 'review'].values\n",
    "    y_train = df.loc[:35000, 'P/N'].values\n",
    "\n",
    "    X_test = df.loc[15000:, 'review'].values\n",
    "    y_test = df.loc[15000:, 'P/N'].values\n",
    "\n",
    "    # 단어장을 만들어주는 객체 생성\n",
    "    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "    # tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer_stopwordsr)\n",
    "    # 데이터를 학습하기 위한 객체\n",
    "    logistic = LogisticRegression(C=10.0, penalty='l2', random_state=0)\n",
    "    # 파이프 라인 설정\n",
    "    pipeline = Pipeline([('vect', tfidf), ('clf', logistic)])\n",
    "\n",
    "    # 학습한다.\n",
    "    stime = time()\n",
    "    print('학습 시작')\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print('학습 종료')\n",
    "    print('총 학습시간 : %d' % (time() - stime))\n",
    "\n",
    "    # 테스트\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"정확도 : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # 성능 확인\n",
    "    y_true = y_test\n",
    "    y_hat = y_pred\n",
    "    print(\"R2 score : \", r2_score(y_true, y_hat))\n",
    "    print(\"mean_absolute_error : \", mean_absolute_error(y_true, y_hat))\n",
    "    print(\"mean_squared_error : \", mean_squared_error(y_true, y_hat))\n",
    "\n",
    "    # 학습이 완료된 객체를 저장한다.\n",
    "    with open('./data/trip_2.dat', 'wb') as fp :\n",
    "        pickle.dump(pipeline, fp)\n",
    "\n",
    "    print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n",
      "학습 종료\n",
      "총 학습시간 : 0\n",
      "정확도 : 0.951\n",
      "R2 score :  0.4861405405405407\n",
      "mean_absolute_error :  0.04864091559370529\n",
      "mean_squared_error :  0.04864091559370529\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "step4_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직접 분류한 데이터셋 2000개 가지고 학습 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sent = pd.read_csv(\"./data/final_sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sent = final_sent.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sent[\"review\"] = final_sent[\"review\"].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sent.to_csv(\"./data/refined_final_sent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_final_sent = refined_final_sent.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_final_sent.to_csv(\"./data/refined_final_sent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>PN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our first dining experience in a north korean ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it was my first meal in north korean restauran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food are generally good tried lunch bulkogi gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food is generally good worth mentioning are ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we ve passed by the place a couple times and w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  PN\n",
       "0  our first dining experience in a north korean ...   1\n",
       "1  it was my first meal in north korean restauran...   1\n",
       "2  food are generally good tried lunch bulkogi gr...   1\n",
       "3  food is generally good worth mentioning are ki...   1\n",
       "4  we ve passed by the place a couple times and w...   1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_final_sent = pd.read_csv(\"./data/refined_final_sent.csv\")\n",
    "refined_final_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "PN        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_final_sent.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_learning() :\n",
    "    # csv 파일에서 데이터를 읽어온다.\n",
    "    df = pd.read_csv('./data/refined_final_sent.csv')\n",
    "    # 테스트, 학습데이터로 나눈다.\n",
    "    X_train = df.loc[:1400, 'review'].values\n",
    "    y_train = df.loc[:1400, 'PN'].values\n",
    "\n",
    "    X_test = df.loc[700:, 'review'].values\n",
    "    y_test = df.loc[700:, 'PN'].values\n",
    "\n",
    "    # 단어장을 만들어주는 객체 생성\n",
    "    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "    # tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer_stopwordsr)\n",
    "    # 데이터를 학습하기 위한 객체\n",
    "    logistic = LogisticRegression(C=10.0, penalty='l2', random_state=0)\n",
    "    \n",
    "    param_grid = [{\"vect__ngram_range\" : [(1,1)], \"vect__stop_words\" : [stopwords, None],\n",
    "              \"vect__tokenizer\" : [tokenizer, tokenizer_porter],\n",
    "              \"clf__C\" : [1.0, 10.0, 100.0]},\n",
    "             {\"vect__ngram_range\" : [(1,1)], \"vect__stop_words\" : [stopwords, None],\n",
    "              \"vect__tokenizer\" : [tokenizer, tokenizer_porter],\n",
    "              \"vect__use_idf\" : [False], \"vect__norm\" : [None],\n",
    "              \"clf__C\" : [1.0, 10.0, 100.0]}]\n",
    "    \n",
    "    \n",
    "    # 파이프 라인 설정\n",
    "    pipeline = Pipeline([('vect', tfidf), ('clf', logistic)])\n",
    "    gs_Ir_tfidf = GridSearchCV(pipeline, param_grid, scoring=\"accuracy\", cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # 학습한다.\n",
    "    stime = time()\n",
    "    print('학습 시작')\n",
    "    gs_Ir_tfidf.fit(X_train, y_train)\n",
    "    \n",
    "    print('학습 종료')\n",
    "    print('총 학습시간 : %d' % (time() - stime))\n",
    "\n",
    "    # 테스트\n",
    "    y_pred = gs_Ir_tfidf.predict(X_test)\n",
    "    print(\"정확도 : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # 성능 확인\n",
    "    y_true = y_test\n",
    "    y_hat = y_pred\n",
    "    print(\"R2 score : \", r2_score(y_true, y_hat))\n",
    "    print(\"mean_absolute_error : \", mean_absolute_error(y_true, y_hat))\n",
    "    print(\"mean_squared_error : \", mean_squared_error(y_true, y_hat))\n",
    "    print(\"best_params : \" , gs_Ir_tfidf.best_params_)\n",
    "\n",
    "    # 학습이 완료된 객체를 저장한다.\n",
    "    with open('./data/trip_3.dat', 'wb') as fp :\n",
    "        pickle.dump(pipeline, fp)\n",
    "\n",
    "    print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./data/trip_3.dat\", \"rb\")\n",
    "model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   19.0s finished\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abl', 'absolut', 'accid', 'accommod', 'accumul', 'actual', 'advanc', 'advis', 'age', 'allow', 'alon', 'alreadi', 'alway', 'amplifi', 'ani', 'anoth', 'anymor', 'anyon', 'anyth', 'apart', 'appear', 'arriv', 'aspect', 'assur', 'attent', 'authent', 'avail', 'avarag', 'averag', 'awar', 'be', 'becam', 'becaus', 'befor', 'begin', 'blame', 'block', 'buildingoutsid', 'busi', 'carri', 'celebr', 'cellophan', 'centr', 'central', 'certainli', 'certifi', 'chanc', 'characterist', 'check', 'chock', 'choic', 'choos', 'citi', 'cloth', 'coke', 'come', 'complet', 'complic', 'condit', 'consid', 'correctli', 'countri', 'coupl', 'courteou', 'cozi', 'crown', 'crystal', 'current', 'custom', 'defin', 'definetli', 'definit', 'definitli', 'defrost', 'delic', 'delv', 'descript', 'dine', 'discov', 'do', 'doe', 'downsid', 'dri', 'drop', 'dure', 'els', 'empti', 'encount', 'environ', 'especi', 'europ', 'eventu', 'everi', 'everyon', 'everyth', 'exactli', 'expect', 'exquisit', 'extens', 'extrem', 'favour', 'feel', 'fool', 'gentl', 'genuinli', 'gladli', 'go', 'goe', 'greet', 'grow', 'ha', 'hand', 'happen', 'hi', 'highli', 'honestli', 'hospit', 'hour', 'hous', 'humbl', 'hungri', 'identifi', 'imagin', 'immedi', 'importantli', 'improv', 'includ', 'increas', 'incred', 'issu', 'it', 'joke', 'kind', 'know', 'larg', 'layer', 'lazi', 'leav', 'list', 'liter', 'locat', 'maintain', 'make', 'manag', 'massiv', 'materi', 'mayb', 'meter', 'mile', 'minc', 'mindblow', 'minut', 'mispronounc', 'morn', 'motiv', 'mum', 'navig', 'nearbi', 'nervou', 'nonsens', 'noth', 'notic', 'obsess', 'occas', 'occass', 'offer', 'offic', 'onc', 'onli', 'opt', 'option', 'ourselv', 'overal', 'overpay', 'pack', 'park', 'particularli', 'peopl', 'perhap', 'pictur', 'piec', 'place', 'plan', 'play', 'pleas', 'plenti', 'plu', 'predominantli', 'prepar', 'present', 'pretti', 'probabl', 'prohibit', 'properli', 'provid', 'quit', 'randomli', 'rang', 'read', 'readi', 'realiz', 'realli', 'recent', 'recip', 'recommend', 'refer', 'rel', 'relat', 'rememb', 'remind', 'request', 'requir', 'reserv', 'respons', 'reveal', 'romant', 'room', 'sampl', 'save', 'seat', 'seem', 'serv', 'set', 'significantli', 'simpl', 'simpli', 'sinc', 'singl', 'sit', 'size', 'skeptic', 'slightli', 'sliver', 'someth', 'somewher', 'sorri', 'stair', 'staircas', 'standard', 'state', 'struggl', 'studi', 'substanti', 'sunni', 'surround', 'suspicion', 'tabl', 'tailor', 'talk', 'temperatur', 'term', 'theme', 'thi', 'thoroughli', 'thu', 'tongu', 'total', 'train', 'travel', 'tricki', 'truli', 'turn', 'type', 'unassum', 'unbeat', 'variat', 'ventil', 'veri', 'vers', 'visit', 'wa', 'wait', 'want', 'wash', 'weak', 'welcom', 'whatev', 'whi', 'woo', 'yea', 'year', 'youngster'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 종료\n",
      "총 학습시간 : 20\n",
      "정확도 : 0.950\n",
      "R2 score :  0.5415471222396104\n",
      "mean_absolute_error :  0.05007704160246533\n",
      "mean_squared_error :  0.05007704160246533\n",
      "best_params :  {'clf__C': 10.0, 'vect__ngram_range': (1, 1), 'vect__stop_words': ['about', 'also', 'and', 'because', 'box', 'dish', 'dishes', 'etc', 'front', 'cashier', 'husband', 'immediately', 'just', 'menu', 'minutes', 'others', 'our', 'relay', 'section', 'some', 'that', 'the', 'their', 'them', 'then', 'this', 'very', 'walked', 'was', 'were', 'what', 'when', 'women', 'busy', 'gotta', 'been', 'here', 'times', 'and', 'this', 'the', 'are', 'there', 'options', 'had', 'have', 'you', 'find', 'authentic', 'pretty', 'choose', 'was', 'parking ', 'were', 'plenty', 'pot', 'dishes', 'they', 'serve', 'free', 'low', 'day', 'cuz', 'eat', 'box', 'today', 'give', 'chance', 'something', 'else', 'really', 'short', 'wife', 'plate', 'always', 'second', 'time', 'very', 'came', 'out', 'thier', 'bowl', 'table', 'still', 'bottom', 'sunny', 'all', 'add', 'some', 'your', 'kept', 'almost', 'definitly', 'friend', 'recently', 'stopped', 'arrived', 'packed', 'long', 'plus', 'including', 'cellophane', 'slivers', 'went', 'night', 'staying', 'when', 'home', 'wide', 'now', 'minutes', 'them', 'that', 'other', 'just', 'their', 'range', 'once', 'car', 'drive', 'miles', 'wanted', 'stop', 'along', 'would', 'waiting', 'stay', 'land', 'people', 'brought', 'half', 'dozen', 'mixes', 'each', 'yeas', 'locations', 'found', 'especially', 'significantly', 'plae', 'two', 'blocks', 'away', 'trained', 'places', 'quite', 'can', 'min', 'years', 'started', 'lived', 'countries', 'myself', 'versed', 'twice', 'week', 'owned', 'own', 'currently', 'has', 'sushi', 'order', 'correctly', 'around', 'couple', 'sooo', 'through', 'sister', 'rest', 'being', 'three', 'ordered', 'huge', 'yakimondo', 'say', 'portions', 'large', 'groups', 'lover', 'due', 'neighbor', 'makes', 'most', 'pass', 'only', 'looking', 'word', 'mouth', 'buildingoutside', 'interior', 'where', 'welcome', 'front', 'opted', 'guest', 'another', 'presentation', 'larger', 'show', 'his', 'work', 'done', 'mizo', 'start', 'while', 'did', 'sample', 'till', 'open', 'seats', 'across', 'street', 'which', 'certainly', 'proclaim', 'thought', 'somewhat', 'amount', 'navigating', 'hole', 'wall', 'gets', 'anything', 'also', 'ask', 'how', 'into', 'probably', 'put', 'anyway', 'yesterday', 'honestly', 'whole', 'its', 'speak', 'corner', 'sick', 'ethnic', 'everything', 'coming', 'kitchen', 'things', 'defrosted', 'properly', 'black', 'below', 'average', 'frozen', 'let', 'down', 'definitely', 'extremely', 'what', 'randomly', 'during', 'our', 'managed', 'past', 'location', 'exterior', 'lot', 'alone', 'single', 'piece', 'gimchitold', 'whether', 'ended', 'takeaway', 'aspects', 'dropped', 'accumulated', 'mother', 'law', 'completely', 'aged', 'finding', 'round', 'fooled', 'highly', 'explain', 'those', 'who', 'tourist', 'itself', 'themed', 'decorations', 'seems', 'delicately', 'ranges', 'udon', 'persons', 'sets', 'fix', 'basement', 'any', 'turning', 'reservation', 'literally', 'meters', 'tram', 'station', 'plain', 'view', 'look', 'fact', 'stairs', 'near', 'helping', 'after', 'step', 'realize', 'setting', 'pleasing', 'decor', 'motives', 'modern', 'lines', 'entered', 'certify', 'personal', 'touch', 'noticed', 'high', 'chair', 'return', 'weekend', 'per', 'noticing', 'accommodation', 'book', 'advance', 'evening', 'upon', 'arrival', 'considered', 'ourselves', 'tables', 'predominantly', 'variations', 'boyfriend', 'clear', 'even', 'joked', 'asking', 'prompt', 'center', 'longer', 'morning', 'sight', 'seeing', 'courteous', 'overpaying', 'gave', 'mispronounced', 'thoroughly', 'trio', 'cokes', 'walking', 'dad', 'took', 'mums', 'house', 'might', 'comfort', 'mean', 'isn', 'either', 'reminded', 'higher', 'because', 'prime', 'hours', 'search', 'gem', 'required', 'minute', 'ride', 'see', 'neighborhood', 'part', 'flat', 'city', 'accept', 'carry', 'imagine', 'ready', 'known', 'customer', 'accommodated', 'requests', 'daughter', 'owner', 'patient', 'help', 'split', 'types', 'non', 'pesto', 'beginning', 'choices', 'end', 'saved', 'tongues', 'every', 'pay', 'sized', 'portion', 'background', 'playing', 'person', 'starter', 'mension', 'sayd', 'does', 'locate', 'environment', 'true', 'stated', 'splendid', 'she', 'sorry', 'expecting', 'layers', 'realized', 'redo', 'both', 'leaves', 'slightly', 'broth', 'standards', 'serving', 'recommending', 'prepared', 'presented', 'characteristics', 'personally', 'her', 'meant', 'immediately', 'much', 'chat', 'woman', 'card', 'actually', 'path', 'means', 'dress', 'before', 'line', 'since', 'hair', 'real', 'speaks', 'simple', 'centrally', 'located', 'english', 'issue', 'owners', 'afternoon', 'four', 'warm', 'biggest', 'cozy', 'making', 'meet', 'enter', 'definetly', 'semi', 'gone', 'particularly', 'available', 'walk', 'downside', 'crowns', 'rooms', 'feels', 'totally', 'knew', 'guess', 'advisable', 'ahead', 'incredibly', 'apartment', 'advisor', 'heart', 'warming', 'door', 'notch', 'area', 'somewhere', 'boxes', 'absolutely', 'frequent', 'eater', 'reference', 'material', 'unassuming', 'arrive', 'nonetheless', 'cash', 'earth', 'abroad', 'exquisite', 'reason', 'conditioning', 'ventilation', 'mindblowing', 'mention', 'hold', 'sitting', 'air', 'ground', 'customers', 'days', 'then', 'doing', 'tricky', 'road', 'avarage', 'definately', 'give', 'soon', 'everyday', 'quite', 'get', 'cloths', 'hanger', 'cute', 'hidden', 'part', 'gladly', 'for', 'czk', 'simply', 'starters', 'allowed', 'importantly', 'mom', 'uber', 'ride', 'walk', 'our', 'group', 'comes', 'aunt', 'owns', 'grew', 'hands', 'school', 'absolute', 'having', 'seen', 'steps', 'nothing', 'quiet', 'partner', 'tray', 'etc', 'searching', 'lie', 'finish', 'centre', 'brought', 'everyone', 'older', 'usually', 'increased', 'evenings', 'booking', 'confirm', 'authenticity', 'luck', 'planned', 'customers', 'kinds', 'stuff', 'centrum', 'going', 'smaller', 'shop', 'overall', 'mix', 'already', 'much', 'past', 'month', 'birthday', 'celebration', 'terms', 'delve', 'below', 'wise', 'attentiveness', 'empty', 'occassion', 'revealed', 'amplified', 'nervous', 'guests', 'seated', 'anyone', 'hello', 'mins', 'happening', 'third', 'somehow', 'crowd', 'youngsters', 'winter', 'jacket', 'live', 'nearby', 'substantially', 'improved', 'jap', 'identify', 'blamed', 'favouring', 'provides', 'extreme', 'only', 'pictures', 'study', 'frequently', 'think', 'eum', 'ppong', 'talking', 'tap', 'exactly', 'remembers', 'visiting', 'placed', 'address', 'speaking', 'dull', 'humble', 'surroundings', 'cuz', 'light', 'hospital', 'suchi', 'further', 'relatively', 'skeptical', 'chocked', 'par', 'letdown', 'tad', 'bland', 'dry', 'why', 'prohibitively', 'either', 'washed', 'downplay', 'extensive', 'thing', 'massive', 'rush', 'touched', 'job', 'growing', 'anymore', 'reservations', 'keep', 'offering', 'reading', 'often', 'nonsense', 'number', 'etnic', 'extra', 'assurance', 'decor', 'thus', 'maybe', 'romantic', 'date', 'yourself', 'gentleman', 'rate', 'five', 'perhaps', 'amounts', 'suspicions', 'confirmed', 'sight', 'crystals', 'struggle', 'hungry', 'taxi', 'man', 'knows', 'occasion', 'able', 'booked', 'dined', 'temperature', 'host', 'checked', 'miss', 'four,', 'correct', 'fat', 'stole', 'gentle', 'town', 'plus', 'move', 'stops', 'prepared', 'played', 'pop', 'spice', 'help', 'personnel', 'girlfriend', 'genuinly', 'version', 'doubt', 'occasional', 'tailored', 'given', 'honest', 'aware', 'missed', 'moving', 'expectations', 'key', 'easiest', 'zizkov', 'staircase', 'map', 'eventually', 'passion', 'othet', 'let', 'plates', 'expecting', 'arugula', 'minced', 'manager', 'fifteen', 'complicated', 'ours', 'stayed', 'hotel', 'relation', 'usual', 'unbeatable', 'appears', 'may', 'tonight', 'europe', 'fluent', 'encountered', 'truly', 'accident', 'randomly', 'living', 'obsessed', 'goes', 'cross', 'moved', 'became', 'lazy', 'whatever', 'responsive', 'regard', 'descriptive', 'listings', 'maintaining', 'wooing', 'evr', 'tourism', 'greeted', 'months', 'traveling', 'happened', 'world', 'recipes', 'cure', 'weakness', 'ower', 'warmth', 'afford', 'fuss', 'forward', 'else', 'office', 'week', 'esp', 'item', 'crowns', 'via', 'returned', 'design', 'discover'], 'vect__tokenizer': <function tokenizer_porter at 0x0000026F520BD3A8>}\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "step4_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적의 파라미터로 모델 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   20.5s finished\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abl', 'absolut', 'accid', 'accommod', 'accumul', 'actual', 'advanc', 'advis', 'age', 'allow', 'alon', 'alreadi', 'alway', 'amplifi', 'ani', 'anoth', 'anymor', 'anyon', 'anyth', 'apart', 'appear', 'arriv', 'aspect', 'assur', 'attent', 'authent', 'avail', 'avarag', 'averag', 'awar', 'be', 'becam', 'becaus', 'befor', 'begin', 'blame', 'block', 'buildingoutsid', 'busi', 'carri', 'celebr', 'cellophan', 'centr', 'central', 'certainli', 'certifi', 'chanc', 'characterist', 'check', 'chock', 'choic', 'choos', 'citi', 'cloth', 'coke', 'come', 'complet', 'complic', 'condit', 'consid', 'correctli', 'countri', 'coupl', 'courteou', 'cozi', 'crown', 'crystal', 'current', 'custom', 'defin', 'definetli', 'definit', 'definitli', 'defrost', 'delic', 'delv', 'descript', 'dine', 'discov', 'do', 'doe', 'downsid', 'dri', 'drop', 'dure', 'els', 'empti', 'encount', 'environ', 'especi', 'europ', 'eventu', 'everi', 'everyon', 'everyth', 'exactli', 'expect', 'exquisit', 'extens', 'extrem', 'favour', 'feel', 'fool', 'gentl', 'genuinli', 'gladli', 'go', 'goe', 'greet', 'grow', 'ha', 'hand', 'happen', 'hi', 'highli', 'honestli', 'hospit', 'hour', 'hous', 'humbl', 'hungri', 'identifi', 'imagin', 'immedi', 'importantli', 'improv', 'includ', 'increas', 'incred', 'issu', 'it', 'joke', 'kind', 'know', 'larg', 'layer', 'lazi', 'leav', 'list', 'liter', 'locat', 'maintain', 'make', 'manag', 'massiv', 'materi', 'mayb', 'meter', 'mile', 'minc', 'mindblow', 'minut', 'mispronounc', 'morn', 'motiv', 'mum', 'navig', 'nearbi', 'nervou', 'nonsens', 'noth', 'notic', 'obsess', 'occas', 'occass', 'offer', 'offic', 'onc', 'onli', 'opt', 'option', 'ourselv', 'overal', 'overpay', 'pack', 'park', 'particularli', 'peopl', 'perhap', 'pictur', 'piec', 'place', 'plan', 'play', 'pleas', 'plenti', 'plu', 'predominantli', 'prepar', 'present', 'pretti', 'probabl', 'prohibit', 'properli', 'provid', 'quit', 'randomli', 'rang', 'read', 'readi', 'realiz', 'realli', 'recent', 'recip', 'recommend', 'refer', 'rel', 'relat', 'rememb', 'remind', 'request', 'requir', 'reserv', 'respons', 'reveal', 'romant', 'room', 'sampl', 'save', 'seat', 'seem', 'serv', 'set', 'significantli', 'simpl', 'simpli', 'sinc', 'singl', 'sit', 'size', 'skeptic', 'slightli', 'sliver', 'someth', 'somewher', 'sorri', 'stair', 'staircas', 'standard', 'state', 'struggl', 'studi', 'substanti', 'sunni', 'surround', 'suspicion', 'tabl', 'tailor', 'talk', 'temperatur', 'term', 'theme', 'thi', 'thoroughli', 'thu', 'tongu', 'total', 'train', 'travel', 'tricki', 'truli', 'turn', 'type', 'unassum', 'unbeat', 'variat', 'ventil', 'veri', 'vers', 'visit', 'wa', 'wait', 'want', 'wash', 'weak', 'welcom', 'whatev', 'whi', 'woo', 'yea', 'year', 'youngster'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 파라미터 계산 종료\n",
      "{'clf__C': 10.0, 'vect__ngram_range': (1, 1), 'vect__stop_words': ['about', 'also', 'and', 'because', 'box', 'dish', 'dishes', 'etc', 'front', 'cashier', 'husband', 'immediately', 'just', 'menu', 'minutes', 'others', 'our', 'relay', 'section', 'some', 'that', 'the', 'their', 'them', 'then', 'this', 'very', 'walked', 'was', 'were', 'what', 'when', 'women', 'busy', 'gotta', 'been', 'here', 'times', 'and', 'this', 'the', 'are', 'there', 'options', 'had', 'have', 'you', 'find', 'authentic', 'pretty', 'choose', 'was', 'parking ', 'were', 'plenty', 'pot', 'dishes', 'they', 'serve', 'free', 'low', 'day', 'cuz', 'eat', 'box', 'today', 'give', 'chance', 'something', 'else', 'really', 'short', 'wife', 'plate', 'always', 'second', 'time', 'very', 'came', 'out', 'thier', 'bowl', 'table', 'still', 'bottom', 'sunny', 'all', 'add', 'some', 'your', 'kept', 'almost', 'definitly', 'friend', 'recently', 'stopped', 'arrived', 'packed', 'long', 'plus', 'including', 'cellophane', 'slivers', 'went', 'night', 'staying', 'when', 'home', 'wide', 'now', 'minutes', 'them', 'that', 'other', 'just', 'their', 'range', 'once', 'car', 'drive', 'miles', 'wanted', 'stop', 'along', 'would', 'waiting', 'stay', 'land', 'people', 'brought', 'half', 'dozen', 'mixes', 'each', 'yeas', 'locations', 'found', 'especially', 'significantly', 'plae', 'two', 'blocks', 'away', 'trained', 'places', 'quite', 'can', 'min', 'years', 'started', 'lived', 'countries', 'myself', 'versed', 'twice', 'week', 'owned', 'own', 'currently', 'has', 'sushi', 'order', 'correctly', 'around', 'couple', 'sooo', 'through', 'sister', 'rest', 'being', 'three', 'ordered', 'huge', 'yakimondo', 'say', 'portions', 'large', 'groups', 'lover', 'due', 'neighbor', 'makes', 'most', 'pass', 'only', 'looking', 'word', 'mouth', 'buildingoutside', 'interior', 'where', 'welcome', 'front', 'opted', 'guest', 'another', 'presentation', 'larger', 'show', 'his', 'work', 'done', 'mizo', 'start', 'while', 'did', 'sample', 'till', 'open', 'seats', 'across', 'street', 'which', 'certainly', 'proclaim', 'thought', 'somewhat', 'amount', 'navigating', 'hole', 'wall', 'gets', 'anything', 'also', 'ask', 'how', 'into', 'probably', 'put', 'anyway', 'yesterday', 'honestly', 'whole', 'its', 'speak', 'corner', 'sick', 'ethnic', 'everything', 'coming', 'kitchen', 'things', 'defrosted', 'properly', 'black', 'below', 'average', 'frozen', 'let', 'down', 'definitely', 'extremely', 'what', 'randomly', 'during', 'our', 'managed', 'past', 'location', 'exterior', 'lot', 'alone', 'single', 'piece', 'gimchitold', 'whether', 'ended', 'takeaway', 'aspects', 'dropped', 'accumulated', 'mother', 'law', 'completely', 'aged', 'finding', 'round', 'fooled', 'highly', 'explain', 'those', 'who', 'tourist', 'itself', 'themed', 'decorations', 'seems', 'delicately', 'ranges', 'udon', 'persons', 'sets', 'fix', 'basement', 'any', 'turning', 'reservation', 'literally', 'meters', 'tram', 'station', 'plain', 'view', 'look', 'fact', 'stairs', 'near', 'helping', 'after', 'step', 'realize', 'setting', 'pleasing', 'decor', 'motives', 'modern', 'lines', 'entered', 'certify', 'personal', 'touch', 'noticed', 'high', 'chair', 'return', 'weekend', 'per', 'noticing', 'accommodation', 'book', 'advance', 'evening', 'upon', 'arrival', 'considered', 'ourselves', 'tables', 'predominantly', 'variations', 'boyfriend', 'clear', 'even', 'joked', 'asking', 'prompt', 'center', 'longer', 'morning', 'sight', 'seeing', 'courteous', 'overpaying', 'gave', 'mispronounced', 'thoroughly', 'trio', 'cokes', 'walking', 'dad', 'took', 'mums', 'house', 'might', 'comfort', 'mean', 'isn', 'either', 'reminded', 'higher', 'because', 'prime', 'hours', 'search', 'gem', 'required', 'minute', 'ride', 'see', 'neighborhood', 'part', 'flat', 'city', 'accept', 'carry', 'imagine', 'ready', 'known', 'customer', 'accommodated', 'requests', 'daughter', 'owner', 'patient', 'help', 'split', 'types', 'non', 'pesto', 'beginning', 'choices', 'end', 'saved', 'tongues', 'every', 'pay', 'sized', 'portion', 'background', 'playing', 'person', 'starter', 'mension', 'sayd', 'does', 'locate', 'environment', 'true', 'stated', 'splendid', 'she', 'sorry', 'expecting', 'layers', 'realized', 'redo', 'both', 'leaves', 'slightly', 'broth', 'standards', 'serving', 'recommending', 'prepared', 'presented', 'characteristics', 'personally', 'her', 'meant', 'immediately', 'much', 'chat', 'woman', 'card', 'actually', 'path', 'means', 'dress', 'before', 'line', 'since', 'hair', 'real', 'speaks', 'simple', 'centrally', 'located', 'english', 'issue', 'owners', 'afternoon', 'four', 'warm', 'biggest', 'cozy', 'making', 'meet', 'enter', 'definetly', 'semi', 'gone', 'particularly', 'available', 'walk', 'downside', 'crowns', 'rooms', 'feels', 'totally', 'knew', 'guess', 'advisable', 'ahead', 'incredibly', 'apartment', 'advisor', 'heart', 'warming', 'door', 'notch', 'area', 'somewhere', 'boxes', 'absolutely', 'frequent', 'eater', 'reference', 'material', 'unassuming', 'arrive', 'nonetheless', 'cash', 'earth', 'abroad', 'exquisite', 'reason', 'conditioning', 'ventilation', 'mindblowing', 'mention', 'hold', 'sitting', 'air', 'ground', 'customers', 'days', 'then', 'doing', 'tricky', 'road', 'avarage', 'definately', 'give', 'soon', 'everyday', 'quite', 'get', 'cloths', 'hanger', 'cute', 'hidden', 'part', 'gladly', 'for', 'czk', 'simply', 'starters', 'allowed', 'importantly', 'mom', 'uber', 'ride', 'walk', 'our', 'group', 'comes', 'aunt', 'owns', 'grew', 'hands', 'school', 'absolute', 'having', 'seen', 'steps', 'nothing', 'quiet', 'partner', 'tray', 'etc', 'searching', 'lie', 'finish', 'centre', 'brought', 'everyone', 'older', 'usually', 'increased', 'evenings', 'booking', 'confirm', 'authenticity', 'luck', 'planned', 'customers', 'kinds', 'stuff', 'centrum', 'going', 'smaller', 'shop', 'overall', 'mix', 'already', 'much', 'past', 'month', 'birthday', 'celebration', 'terms', 'delve', 'below', 'wise', 'attentiveness', 'empty', 'occassion', 'revealed', 'amplified', 'nervous', 'guests', 'seated', 'anyone', 'hello', 'mins', 'happening', 'third', 'somehow', 'crowd', 'youngsters', 'winter', 'jacket', 'live', 'nearby', 'substantially', 'improved', 'jap', 'identify', 'blamed', 'favouring', 'provides', 'extreme', 'only', 'pictures', 'study', 'frequently', 'think', 'eum', 'ppong', 'talking', 'tap', 'exactly', 'remembers', 'visiting', 'placed', 'address', 'speaking', 'dull', 'humble', 'surroundings', 'cuz', 'light', 'hospital', 'suchi', 'further', 'relatively', 'skeptical', 'chocked', 'par', 'letdown', 'tad', 'bland', 'dry', 'why', 'prohibitively', 'either', 'washed', 'downplay', 'extensive', 'thing', 'massive', 'rush', 'touched', 'job', 'growing', 'anymore', 'reservations', 'keep', 'offering', 'reading', 'often', 'nonsense', 'number', 'etnic', 'extra', 'assurance', 'decor', 'thus', 'maybe', 'romantic', 'date', 'yourself', 'gentleman', 'rate', 'five', 'perhaps', 'amounts', 'suspicions', 'confirmed', 'sight', 'crystals', 'struggle', 'hungry', 'taxi', 'man', 'knows', 'occasion', 'able', 'booked', 'dined', 'temperature', 'host', 'checked', 'miss', 'four,', 'correct', 'fat', 'stole', 'gentle', 'town', 'plus', 'move', 'stops', 'prepared', 'played', 'pop', 'spice', 'help', 'personnel', 'girlfriend', 'genuinly', 'version', 'doubt', 'occasional', 'tailored', 'given', 'honest', 'aware', 'missed', 'moving', 'expectations', 'key', 'easiest', 'zizkov', 'staircase', 'map', 'eventually', 'passion', 'othet', 'let', 'plates', 'expecting', 'arugula', 'minced', 'manager', 'fifteen', 'complicated', 'ours', 'stayed', 'hotel', 'relation', 'usual', 'unbeatable', 'appears', 'may', 'tonight', 'europe', 'fluent', 'encountered', 'truly', 'accident', 'randomly', 'living', 'obsessed', 'goes', 'cross', 'moved', 'became', 'lazy', 'whatever', 'responsive', 'regard', 'descriptive', 'listings', 'maintaining', 'wooing', 'evr', 'tourism', 'greeted', 'months', 'traveling', 'happened', 'world', 'recipes', 'cure', 'weakness', 'ower', 'warmth', 'afford', 'fuss', 'forward', 'else', 'office', 'week', 'esp', 'item', 'crowns', 'via', 'returned', 'design', 'discover'], 'vect__tokenizer': <function tokenizer_porter at 0x0000026F520BD3A8>}\n",
      "테스트 정확도: 0.950\n"
     ]
    }
   ],
   "source": [
    "# csv 파일에서 데이터를 읽어온다.\n",
    "df = pd.read_csv('./data/refined_final_sent.csv')\n",
    "# 테스트, 학습데이터로 나눈다.\n",
    "X_train = df.loc[:1400, 'review'].values\n",
    "y_train = df.loc[:1400, 'PN'].values\n",
    "\n",
    "X_test = df.loc[700:, 'review'].values\n",
    "y_test = df.loc[700:, 'PN'].values\n",
    "\n",
    "# 단어장을 만들어주는 객체 생성\n",
    "tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "# tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer_stopwordsr)\n",
    "\n",
    "Ir_tfidf = Pipeline([\"vect\"])\n",
    "# 데이터를 학습하기 위한 객체\n",
    "logistic = LogisticRegression(C=10.0, penalty='l2', random_state=0)\n",
    "\n",
    "\n",
    "# 파이프 라인 설정\n",
    "pipeline = Pipeline([('vect', tfidf), ('clf', logistic)])\n",
    "\n",
    "# 학습한다.\n",
    "stime = time()\n",
    "print('학습 시작')\n",
    "gs_Ir_tfidf.fit(X_train, y_train)\n",
    "\n",
    "print('최종 파라미터 계산 종료')\n",
    "print(gs_Ir_tfidf.best_params_)\n",
    "\n",
    "clf = gs_Ir_tfidf.best_estimator_\n",
    "print(\"테스트 정확도: %.3f\" % clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gs_Ir_tfidf, open(os.path.join(\"data\", \"tok_model.pkl\"), \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "curDir = os.getcwd()\n",
    "clf = pickle.load(open(os.path.join(curDir, \"data\", \"tok_model.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abl', 'absolut', 'accid', 'accommod', 'accumul', 'actual', 'advanc', 'advis', 'age', 'allow', 'alon', 'alreadi', 'alway', 'amplifi', 'ani', 'anoth', 'anymor', 'anyon', 'anyth', 'apart', 'appear', 'arriv', 'aspect', 'assur', 'attent', 'authent', 'avail', 'avarag', 'averag', 'awar', 'be', 'becam', 'becaus', 'befor', 'begin', 'blame', 'block', 'buildingoutsid', 'busi', 'carri', 'celebr', 'cellophan', 'centr', 'central', 'certainli', 'certifi', 'chanc', 'characterist', 'check', 'chock', 'choic', 'choos', 'citi', 'cloth', 'coke', 'come', 'complet', 'complic', 'condit', 'consid', 'correctli', 'countri', 'coupl', 'courteou', 'cozi', 'crown', 'crystal', 'current', 'custom', 'defin', 'definetli', 'definit', 'definitli', 'defrost', 'delic', 'delv', 'descript', 'dine', 'discov', 'do', 'doe', 'downsid', 'dri', 'drop', 'dure', 'els', 'empti', 'encount', 'environ', 'especi', 'europ', 'eventu', 'everi', 'everyon', 'everyth', 'exactli', 'expect', 'exquisit', 'extens', 'extrem', 'favour', 'feel', 'fool', 'gentl', 'genuinli', 'gladli', 'go', 'goe', 'greet', 'grow', 'ha', 'hand', 'happen', 'hi', 'highli', 'honestli', 'hospit', 'hour', 'hous', 'humbl', 'hungri', 'identifi', 'imagin', 'immedi', 'importantli', 'improv', 'includ', 'increas', 'incred', 'issu', 'it', 'joke', 'kind', 'know', 'larg', 'layer', 'lazi', 'leav', 'list', 'liter', 'locat', 'maintain', 'make', 'manag', 'massiv', 'materi', 'mayb', 'meter', 'mile', 'minc', 'mindblow', 'minut', 'mispronounc', 'morn', 'motiv', 'mum', 'navig', 'nearbi', 'nervou', 'nonsens', 'noth', 'notic', 'obsess', 'occas', 'occass', 'offer', 'offic', 'onc', 'onli', 'opt', 'option', 'ourselv', 'overal', 'overpay', 'pack', 'park', 'particularli', 'peopl', 'perhap', 'pictur', 'piec', 'place', 'plan', 'play', 'pleas', 'plenti', 'plu', 'predominantli', 'prepar', 'present', 'pretti', 'probabl', 'prohibit', 'properli', 'provid', 'quit', 'randomli', 'rang', 'read', 'readi', 'realiz', 'realli', 'recent', 'recip', 'recommend', 'refer', 'rel', 'relat', 'rememb', 'remind', 'request', 'requir', 'reserv', 'respons', 'reveal', 'romant', 'room', 'sampl', 'save', 'seat', 'seem', 'serv', 'set', 'significantli', 'simpl', 'simpli', 'sinc', 'singl', 'sit', 'size', 'skeptic', 'slightli', 'sliver', 'someth', 'somewher', 'sorri', 'stair', 'staircas', 'standard', 'state', 'struggl', 'studi', 'substanti', 'sunni', 'surround', 'suspicion', 'tabl', 'tailor', 'talk', 'temperatur', 'term', 'theme', 'thi', 'thoroughli', 'thu', 'tongu', 'total', 'train', 'travel', 'tricki', 'truli', 'turn', 'type', 'unassum', 'unbeat', 'variat', 'ventil', 'veri', 'vers', 'visit', 'wa', 'wait', 'want', 'wash', 'weak', 'welcom', 'whatev', 'whi', 'woo', 'yea', 'year', 'youngster'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도:  0.949923\n",
      "영문으로 리뷰를 작성하세요: I am familiar with Korean food. My mother is Japanese, so I grew up around Asian foods. I was excited when I found this little place just a few blocks from where I was working. I was traveling on business on Tampa for the week and my husband came along.\\n\\nThe place is easy to miss. It looks like a little dive but it is cute inside and has more seating than you think. I liked all of the wood seating. I didn't expect it to look so nice inside. We arrived just before the after-5pm rush-hour so we got drinks and appetizers quickly. Fried squid strips were bland but the sauces they served with changed that. The vegetable dumplings were okay, I would prefer them to be steamed rather than fried.\\n\\nI knew we'd have some issues with the menu as we are not meat eaters and Korean food incorporates a lot of pork, beef and things like oxtail. Most of the places I have been are willing to substitute tofu or calamari in dishes but they wouldn't. The waitress looked at us funny when I asked of the chap chae could have tofu instead of the pork, and said they could not. It was getting busy and we ended up ordering a noodle dish for two with vegetables and calamari strips. We asked for this to be as mild as possible, knowing Korean food is rather spicy to begin with. The portions were huge and I love all the little side dishes that come with entrees. The sauce with the noodles was very thick and rich and spicy...we couldn't eat a lot of it.\\n\\nThe place was buzzing with people and the waitress was not good about checking on us and refilling water. I would say this plus the unwillingness for her to check to see if the chef would substitute for us turned us off but I would recommend this greatly to meat eaters. I saw plates of kalbi and bulgoki going by and they looked fabulous. Too bad you can't bbq your own here. A spot near Chicago we've been to a couple of times includes shrimp on the bbq menu.\n",
      "예측: 긍정적 의견\n",
      "확률: 72.967%\n",
      "영문으로 리뷰를 작성하세요: Excellent korean restaurant with tasteful kimchi. Rough interior and quick service. The reataurant seems really popular and reservation is a must. Their online reservation system works well.\n",
      "예측: 긍정적 의견\n",
      "확률: 89.563%\n",
      "영문으로 리뷰를 작성하세요: The owners are super nice and accommodating. If you are eating in, you can pay after you finish your meal. This is a small place and ideally for take out. I ate in and there were only a few seats (4-5) so it can get cramped. However, it is a pretty quick turn-around. \\r\\n\\r\\nThe food is cooked fresh and on the spot. The Beef Rice Bowl is generously portioned with rice, glass noodles, beef, egg, deep fried gyozas, seaweed and assorted vegetables. There are additional flavors from the sauces and it is very well put together. \\r\\n\\r\\nThe pork bone soup was flavorful and the spice level was on point. The meat falls off the bones!\\r\\n\\r\\nOverall, I would recommend coming here for take out (especially the rice bowls). They allow you to pick the sides since they have a variety available! The portions are great for their price point. This restaurant may be easy to miss since it is tucked in the small plaza next to Wendy's and Tim Horton's.\n",
      "예측: 긍정적 의견\n",
      "확률: 98.420%\n",
      "영문으로 리뷰를 작성하세요: This is the BEST value, except you're not sacrificing any food/taste for getting a cheap meal.\n",
      "예측: 긍정적 의견\n",
      "확률: 79.883%\n",
      "영문으로 리뷰를 작성하세요: They are rude from start to finish, despite never being busy they will always rush you, they won't listen to what you are asking, they will dump the food on your plate and send you home angry. The food has gotten me sick twice, the people have gotten me mad every time. I asked them to put my spring rolls in a separate box so they don't get sauce on them, he said no threw it In the same plate and then poured sauce on it. They have horrible customer service and bad food preparation practices, if I knew somebody in the health service industry I would report this place immediately. The owners carelessness had reached new heights. The food now comes burnt and it definitely doesn't feel clean. He used the same tongs for raw, cooked meat, then used it on the French fries. They are rude from start to finish, despite never being busy they will always rush you, they won't listen to what you are asking, they will dump the food on your plate and send you home angry. The food has gotten me sick twice, the people have gotten me mad every time. I asked them to put my spring rolls in a separate box so they don't get sauce on them, he said no threw it In the same plate and then poured sauce on it. They have horrible customer service and bad food preparation practices, if I knew somebody in the health service industry I would report this place immediately. Then because the sandwich was too big he used the same tongues he used for raw and cooked meats to smush my burnt bun down to make it fit. Everything was great, except for the fact that they forgot to tell us to ring the buzzer for service, so we ended up waiting a long time for everything. When we finally figured it out, it was almost at the end of our meal! \n",
      "예측: 긍정적 의견\n",
      "확률: 55.233%\n",
      "영문으로 리뷰를 작성하세요: Spicy rice cake: this was good, however it was too spicy - I underestimated the spice level.\n",
      "예측: 긍정적 의견\n",
      "확률: 88.995%\n",
      "영문으로 리뷰를 작성하세요: The food wasn't bad, but the service was really terrible. Bad experience!\n",
      "예측: 부정적 의견\n",
      "확률: 62.420%\n",
      "영문으로 리뷰를 작성하세요: I hope this helps. The grill doesn't get hot enough ... thinly sliced brisket took 15min to cook and and I like my beef medium rare.  My waiter was terrible, he felt some type of way when I told him I don't need him to cook for me because he didnt look like knew what he was doing. Then had the nerve to tell me I didn't know what I was doing... when I left I had raw meat on the grill that took too long to cook and he tried to charge me extra ... This is the first Korean bbq in the state of North Carolina if I'm not mistaken. so I assume most here never had experience good Korean bbq.\n",
      "예측: 긍정적 의견\n",
      "확률: 56.923%\n",
      "영문으로 리뷰를 작성하세요: All-in-all, the place isn't terrible and the service was good. It's just not my kind of place. \n",
      "예측: 부정적 의견\n",
      "확률: 87.764%\n",
      "영문으로 리뷰를 작성하세요: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mmsg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[1;34m(self, flags, copy, track)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;31m# have first part already, only loop while more to receive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-6e63c6826d9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"영문으로 리뷰를 작성하세요: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtxt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         )\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"./data/refined_final_sent.csv\")\n",
    "\n",
    "X_train = df.loc[:1400, 'review'].values\n",
    "y_train = df.loc[:1400, 'PN'].values\n",
    "\n",
    "X_test = df.loc[700:, 'review'].values\n",
    "y_test = df.loc[700:, 'PN'].values\n",
    "\n",
    "f = open(\"./data/trip_3.dat\", \"rb\")\n",
    "model = pickle.load(f)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"테스트 정확도: % 3f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "label = {0:\"부정적 의견\", 1:\"긍정적 의견\"}\n",
    "\n",
    "while True:\n",
    "    txt = input(\"영문으로 리뷰를 작성하세요: \")\n",
    "    if txt == \"\":\n",
    "        break\n",
    "        \n",
    "    example = [txt]\n",
    "    pirnt(\"예측: %s\\n확률: %.3f%%\" % (label[clf.predict(example)[0]],\n",
    "                                 np.max(clf.predict_proba(example))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 분류한 데이터셋으로 학습시킨 모델로 긍정 부정 리뷰 나눠보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n",
      "학습 종료\n",
      "총 학습시간 : 0\n",
      "정확도 : 0.942\n",
      "R2 score :  0.7678386350952723\n",
      "mean_absolute_error :  0.05803571428571429\n",
      "mean_squared_error :  0.05803571428571429\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute '_best_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d760fad4a89d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mean_absolute_error : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mean_squared_error : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_params :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_best_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# 학습이 완료된 객체를 저장한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute '_best_params'"
     ]
    }
   ],
   "source": [
    "# csv 파일에서 데이터를 읽어온다.\n",
    "df = pd.read_csv(\"./data/PN_dataset/dataset_1600.csv\")\n",
    "# 테스트, 학습데이터로 나눈다.\n",
    "X_train = df.loc[:1120, 'review'].values\n",
    "y_train = df.loc[:1120, 'PN'].values\n",
    "\n",
    "X_test = df.loc[480:, 'review'].values\n",
    "y_test = df.loc[480:, 'PN'].values\n",
    "\n",
    "# 단어장을 만들어주는 객체 생성\n",
    "tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "# tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer_stopwordsr)\n",
    "# 데이터를 학습하기 위한 객체\n",
    "logistic = LogisticRegression(C=10.0, penalty='l2', random_state=0)\n",
    "# 파이프 라인 설정\n",
    "pipeline = Pipeline([('vect', tfidf), ('clf', logistic)])\n",
    "\n",
    "# 학습한다.\n",
    "stime = time()\n",
    "print('학습 시작')\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('학습 종료')\n",
    "print('총 학습시간 : %d' % (time() - stime))\n",
    "\n",
    "# 테스트\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"정확도 : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 성능 확인\n",
    "y_true = y_test\n",
    "y_hat = y_pred\n",
    "print(\"R2 score : \", r2_score(y_true, y_hat))\n",
    "print(\"mean_absolute_error : \", mean_absolute_error(y_true, y_hat))\n",
    "print(\"mean_squared_error : \", mean_squared_error(y_true, y_hat))\n",
    "\n",
    "# 학습이 완료된 객체를 저장한다.\n",
    "with open('./data/trip_1600.dat', 'wb') as fp :\n",
    "    pickle.dump(pipeline, fp)\n",
    "\n",
    "print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline, open(os.path.join(\"data\", \"jik_model_1600.pkl\"), \"wb\"), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "curDir = os.getcwd()\n",
    "clf = pickle.load(open(os.path.join(curDir, \"data\", \"jik_model_1600.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 정확도:  0.941964\n",
      "영문으로 리뷰를 작성하세요: Authentic Korean BBQ restaurant--not the AYCE kind! The quality of the meat was good and better than normal AYCE.\\r\\n\\r\\nMy husband and I came here for dinner on a Monday evening--we made reservations but definitely not as busy as weekends as we've tried to wait in line in the past but didn't have the patience.\\r\\n\\r\\nThe dim lighting made it challenging to cook the food on the grill and know when it would be cooked. I may have undercooked some of it or mixed the tongs and felt a bit sick the next day, so definitely make sure you cook it enough!\\r\\n\\r\\nThe side dishes were great. The portions are large enough that one order of any meat is enough for one person, so we got one order of boneless short ribs and one of pork shoulder.  We also ordered a rice noodle soup as we weren't sure if it would be enough food.\\r\\n\\r\\nThe total came to about $65-$70 in total without any drinks\n",
      "예측: 부정적 의견\n",
      "확률: 57.966%\n",
      "영문으로 리뷰를 작성하세요: i think it's not that great food\n",
      "예측: 부정적 의견\n",
      "확률: 80.927%\n",
      "영문으로 리뷰를 작성하세요: the weahter was rainy so we went to the our favorite restaurant that's our favorit so we expected the yummy fooods. That day, the taste was not enough to us, but whatever.\n",
      "예측: 부정적 의견\n",
      "확률: 81.946%\n",
      "영문으로 리뷰를 작성하세요: Never coming back again. The service is horrible and the meat is not good at all.   There are only 2 waitress total for the whole restaurant on a Saturday.  We sat here for 15 mins before she came to get our order.   Also you can only order 2 dishes at a time with all you can eat.  With the super slow and unfriendly service.  This has been a fairly painful meal for us.   And the food really isn't good. The meat was so sweet and the side dishes were not yummy at all.\n",
      "예측: 부정적 의견\n",
      "확률: 83.942%\n",
      "영문으로 리뷰를 작성하세요: The atmosphere is very intimate during the evenings and cozy during the summertime on the terrace. The food is very good and has never disappointed. Sizzling hot and always fresh, but my favorite is their homemade kimchi. It was so good, I ordered a second bowl.\n",
      "예측: 긍정적 의견\n",
      "확률: 68.086%\n",
      "영문으로 리뷰를 작성하세요: I find the prices tend to be a bit high, but that's not going to stop me from eating what I enjoy. However, during my last visit, we had such horrible and slow service, I am not sure how I feel about coming back again. The waiter took over 20 minutes to take our order and barely ever came to check out is. Water was barely refilled and we had to wait even longer to get our bill. We became so impatient that we just cancelled the rest of the order after 3 of our plates arrived and went elsewhere instead.\n",
      "예측: 부정적 의견\n",
      "확률: 94.892%\n",
      "영문으로 리뷰를 작성하세요: \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"./data/PN_dataset/dataset_1600.csv\")\n",
    "\n",
    "X_train = df.loc[:1120, 'review'].values\n",
    "y_train = df.loc[:1120, 'PN'].values\n",
    "\n",
    "X_test = df.loc[480:, 'review'].values\n",
    "y_test = df.loc[480:, 'PN'].values\n",
    "\n",
    "curDir = os.getcwd()\n",
    "clf = pickle.load(open(os.path.join(curDir, \"data\", \"jik_model_1600.pkl\"), \"rb\"))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"테스트 정확도: % 3f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "label = {0:\"부정적 의견\", 1:\"긍정적 의견\"}\n",
    "\n",
    "while True:\n",
    "    txt = input(\"영문으로 리뷰를 작성하세요: \")\n",
    "    if txt == \"\":\n",
    "        break\n",
    "        \n",
    "    example = [txt]\n",
    "    print(\"예측: %s\\n확률: %.3f%%\" % (label[clf.predict(example)[0]],\n",
    "                                 np.max(clf.predict_proba(example))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직접 만든 stopward로 머신러닝 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['about','also', 'and','because','box','dish','dishes','etc','front','cashier', \"husband\", 'immediately','just','menu', 'minutes','others',\n",
    "'our','relay','section', 'some', 'that', 'the', 'their','them', 'then', 'this', 'very', 'walked', 'was', 'were','what', 'when', 'women','busy','gotta','been','here', 'times', 'and', 'this','the','are',\n",
    "'there','options','had','have','you','find','authentic','pretty','choose',\n",
    "'was','parking ','were','plenty','pot','dishes','they','serve','free','low',\n",
    "'day','cuz','eat','box','today','give','chance','something','else','really','short',\n",
    "'wife','plate','always','second','time','very','came','out','thier',\n",
    "'bowl','table','still','bottom','sunny','all','add','some','your','kept','almost',\n",
    "'definitly','friend','recently','stopped','arrived','packed','long','plus','including',\n",
    "'cellophane','slivers','went','night','staying','when','home','wide','now','minutes',\n",
    "'them','that','other','just','their','range','once','car','drive','miles','wanted',\n",
    "'stop','along','would','waiting','stay','land','people','brought','half',\n",
    "'dozen','mixes','each','yeas','locations','found','especially','significantly','plae',\n",
    "'two','blocks','away','trained','places','quite','can','min','years','started','lived',\n",
    "'countries','myself','versed','twice','week','owned','own','currently','has','sushi',\n",
    "'order','correctly','around','couple','sooo','through','sister',\n",
    "'rest','being','three','ordered','huge','yakimondo','say','portions','large','groups',\n",
    "'lover','due','neighbor','makes','most','pass','only','looking','word','mouth','building'\n",
    "'outside','interior','where','welcome','front','opted','guest','another','presentation',\n",
    "'larger','show','his','work','done','mizo','start','while','did','sample',\n",
    "'till','open','seats','across','street','which','certainly','proclaim','thought',\n",
    "'somewhat','amount','navigating','hole','wall','gets','anything','also','ask','how',\n",
    "'into','probably','put','anyway','yesterday','honestly','whole','its','speak',\n",
    "'corner','sick','ethnic','everything','coming','kitchen','things','defrosted',\n",
    "'properly','black','below','average','frozen','let','down','definitely','extremely',\n",
    "'what','randomly','during','our','managed','past','location','exterior','lot',\n",
    "'alone','single','piece','gimchi''told','whether','ended','takeaway','aspects',\n",
    "'dropped','accumulated','mother','law','completely','aged','finding','round','fooled',\n",
    "'highly','explain','those','who','tourist','itself','themed','decorations','seems',\n",
    "'delicately','ranges','udon','persons','sets','fix','basement','any','turning',\n",
    "'reservation','literally','meters','tram','station','plain','view','look',\n",
    "'fact','stairs','near','helping','after','step','realize','setting','pleasing',\n",
    "'decor','motives','modern','lines','entered','certify','personal','touch','noticed',\n",
    "'high','chair','return','weekend','per','noticing','accommodation','book','advance',\n",
    "'evening','upon','arrival','considered','ourselves','tables','predominantly', 'variations',\n",
    "'boyfriend','clear','even','joked','asking','prompt','center','longer',\n",
    "'morning','sight','seeing','courteous','overpaying','gave','mispronounced',\n",
    "'thoroughly','trio','cokes','walking','dad','took','mums','house','might','comfort',\n",
    "'mean','isn','either','reminded','higher','because','prime','hours','search','gem',\n",
    "'required','minute','ride','see','neighborhood','part','flat','city','accept',\n",
    "'carry','imagine','ready','known','customer','accommodated','requests','daughter',\n",
    "'owner','patient','help','split','types','non','pesto','beginning','choices',\n",
    "'end','saved','tongues','every','pay','sized','portion','background','playing',\n",
    "'person','starter', 'mension','sayd','does','locate','environment',\n",
    "'true','stated','splendid','she','sorry','expecting','layers','realized',\n",
    "'redo','both','leaves','slightly','broth','standards','serving','recommending',\n",
    "'prepared','presented','characteristics','personally','her','meant','immediately',\n",
    "'much','chat','woman','card','actually','path','means','dress','before','line',\n",
    "'since','hair','real','speaks','simple','centrally','located','english',\n",
    "'issue','owners','afternoon','four','warm','biggest','cozy','making','meet',\n",
    "'enter','definetly','semi','gone','particularly','available',\n",
    "'walk','downside','crowns','rooms','feels','totally','knew', 'guess',\n",
    "'advisable','ahead','incredibly','apartment','advisor','heart','warming','door',\n",
    "'notch','area','somewhere','boxes','absolutely','frequent','eater','reference',\n",
    "'material','unassuming','arrive','nonetheless','cash','earth','abroad','exquisite',\n",
    "'reason','conditioning','ventilation','mindblowing','mention','hold','sitting',\n",
    "'air','ground','customers','days','then','doing','tricky','road','avarage','definately',\n",
    "'give','soon','everyday','quite','get','cloths','hanger','cute','hidden','part',\n",
    "'gladly','for','czk','simply','starters','allowed','importantly','mom', 'uber','ride','walk',\n",
    "'our','group','comes','aunt','owns','grew','hands','school','absolute','having','seen',\n",
    "'steps','nothing','quiet','partner','tray','etc','searching','lie','finish','centre',\n",
    "'brought','everyone','older','usually', 'increased','evenings','booking','confirm',\n",
    "'authenticity','luck','planned','customers','kinds','stuff','centrum','going','smaller',\n",
    "'shop','overall','mix','already','much','past','month','birthday','celebration','terms',\n",
    "'delve','below','wise','attentiveness','empty','occassion','revealed','amplified',\n",
    "'nervous','guests','seated','anyone','hello','mins','happening','third','somehow',\n",
    "'crowd','youngsters','winter','jacket','live','nearby','substantially','improved',\n",
    "'jap','identify','blamed','favouring','provides','extreme','only','pictures',\n",
    "'study','frequently','think','eum','ppong','talking','tap','exactly','remembers',\n",
    "'visiting','placed','address','speaking','dull','humble','surroundings','cuz',\n",
    "'light','hospital','suchi','further','relatively','skeptical','chocked','par',\n",
    "'letdown','tad','bland','dry','why','prohibitively','either','washed','downplay',\n",
    "'extensive','thing','massive','rush','touched','job','growing','anymore','reservations',\n",
    "'keep','offering','reading','often','nonsense','number','etnic','extra','assurance',\n",
    "'decor','thus','maybe','romantic','date','yourself','gentleman','rate','five','perhaps',\n",
    "'amounts','suspicions','confirmed','sight','crystals','struggle','hungry','taxi',\n",
    "'man','knows','occasion','able','booked','dined','temperature','host','checked',\n",
    "'miss','four,','correct','fat','stole','gentle','town','plus','move','stops',\n",
    "'prepared','played','pop','spice','help','personnel','girlfriend','genuinly','version',\n",
    "'doubt','occasional','tailored','given','honest','aware','missed','moving','expectations',\n",
    "'key','easiest','zizkov','staircase','map','eventually','passion','othet','let',\n",
    "'plates','expecting','arugula','minced','manager','fifteen','complicated',\n",
    "'ours','stayed','hotel','relation','usual','unbeatable','appears','may','tonight',\n",
    "'europe','fluent','encountered','truly', 'accident','randomly','living','obsessed',\n",
    "'goes','cross','moved','became','lazy','whatever','responsive','regard','descriptive',\n",
    "'listings','maintaining','wooing','evr','tourism','greeted','months','traveling',\n",
    "'happened','world','recipes','cure','weakness','ower','warmth','afford','fuss',\n",
    "'forward','else','office','week','esp','item','crowns','via','returned',\n",
    "'design','discover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step5_learning() :\n",
    "    # csv 파일에서 데이터를 읽어온다.\n",
    "    df = pd.read_csv('./data/refined_final_sent.csv')\n",
    "    # 테스트, 학습데이터로 나눈다.\n",
    "    X_train = df.loc[:1400, 'review'].values\n",
    "    y_train = df.loc[:1400, 'PN'].values\n",
    "\n",
    "    X_test = df.loc[700:, 'review'].values\n",
    "    y_test = df.loc[700:, 'PN'].values\n",
    "    \n",
    "    tfidf = TfidfVectorizer(lowercase=False)\n",
    "    \n",
    "    param_grid = [{\"vect__ngram_range\" : [(1,1)], \"vect__stop_words\" : [stopwords, None],\n",
    "                  \"vect__tokenizer\" : [tokenizer, tokenizer_porter],\n",
    "                  \"clf__C\" : [1.0, 10.0, 100.0]},\n",
    "                 {\"vect__ngram_range\" : [(1,1)], \"vect__stop_words\" : [stopwords, None],\n",
    "                  \"vect__tokenizer\" : [tokenizer, tokenizer_porter],\n",
    "                  \"vect__use_idf\" : [False], \"vect__norm\" : [None],\n",
    "                  \"clf__C\" : [1.0, 10.0, 100.0]}]\n",
    "    \n",
    "    Ir_tfidf = Pipeline([(\"vect\", tfidf), (\"clf\", LogisticRegression(random_state=0))])\n",
    "    gs_Ir_tfidf = GridSearchCV(Ir_tfidf, param_grid, scoring=\"accuracy\", cv=5, verbose=1, n_jobs=-1)\n",
    "    \n",
    "    gs_Ir_tfidf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"최적 파라미터 계산 종료\")\n",
    "    print(gs_Ir_tfidf.best_params_)\n",
    "    \n",
    "    clf = gs_Ir_tfidf.best_estimator_\n",
    "    print(\"테스트 정확도 : %.3f\" %clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   20.0s finished\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abl', 'absolut', 'accid', 'accommod', 'accumul', 'actual', 'advanc', 'advis', 'age', 'allow', 'alon', 'alreadi', 'alway', 'amplifi', 'ani', 'anoth', 'anymor', 'anyon', 'anyth', 'apart', 'appear', 'arriv', 'aspect', 'assur', 'attent', 'authent', 'avail', 'avarag', 'averag', 'awar', 'be', 'becam', 'becaus', 'befor', 'begin', 'blame', 'block', 'buildingoutsid', 'busi', 'carri', 'celebr', 'cellophan', 'centr', 'central', 'certainli', 'certifi', 'chanc', 'characterist', 'check', 'chock', 'choic', 'choos', 'citi', 'cloth', 'coke', 'come', 'complet', 'complic', 'condit', 'consid', 'correctli', 'countri', 'coupl', 'courteou', 'cozi', 'crown', 'crystal', 'current', 'custom', 'defin', 'definetli', 'definit', 'definitli', 'defrost', 'delic', 'delv', 'descript', 'dine', 'discov', 'do', 'doe', 'downsid', 'dri', 'drop', 'dure', 'els', 'empti', 'encount', 'environ', 'especi', 'europ', 'eventu', 'everi', 'everyon', 'everyth', 'exactli', 'expect', 'exquisit', 'extens', 'extrem', 'favour', 'feel', 'fool', 'gentl', 'genuinli', 'gladli', 'go', 'goe', 'greet', 'grow', 'ha', 'hand', 'happen', 'hi', 'highli', 'honestli', 'hospit', 'hour', 'hous', 'humbl', 'hungri', 'identifi', 'imagin', 'immedi', 'importantli', 'improv', 'includ', 'increas', 'incred', 'issu', 'it', 'joke', 'kind', 'know', 'larg', 'layer', 'lazi', 'leav', 'list', 'liter', 'locat', 'maintain', 'make', 'manag', 'massiv', 'materi', 'mayb', 'meter', 'mile', 'minc', 'mindblow', 'minut', 'mispronounc', 'morn', 'motiv', 'mum', 'navig', 'nearbi', 'nervou', 'nonsens', 'noth', 'notic', 'obsess', 'occas', 'occass', 'offer', 'offic', 'onc', 'onli', 'opt', 'option', 'ourselv', 'overal', 'overpay', 'pack', 'park', 'particularli', 'peopl', 'perhap', 'pictur', 'piec', 'place', 'plan', 'play', 'pleas', 'plenti', 'plu', 'predominantli', 'prepar', 'present', 'pretti', 'probabl', 'prohibit', 'properli', 'provid', 'quit', 'randomli', 'rang', 'read', 'readi', 'realiz', 'realli', 'recent', 'recip', 'recommend', 'refer', 'rel', 'relat', 'rememb', 'remind', 'request', 'requir', 'reserv', 'respons', 'reveal', 'romant', 'room', 'sampl', 'save', 'seat', 'seem', 'serv', 'set', 'significantli', 'simpl', 'simpli', 'sinc', 'singl', 'sit', 'size', 'skeptic', 'slightli', 'sliver', 'someth', 'somewher', 'sorri', 'stair', 'staircas', 'standard', 'state', 'struggl', 'studi', 'substanti', 'sunni', 'surround', 'suspicion', 'tabl', 'tailor', 'talk', 'temperatur', 'term', 'theme', 'thi', 'thoroughli', 'thu', 'tongu', 'total', 'train', 'travel', 'tricki', 'truli', 'turn', 'type', 'unassum', 'unbeat', 'variat', 'ventil', 'veri', 'vers', 'visit', 'wa', 'wait', 'want', 'wash', 'weak', 'welcom', 'whatev', 'whi', 'woo', 'yea', 'year', 'youngster'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 파라미터 계산 종료\n",
      "{'clf__C': 10.0, 'vect__ngram_range': (1, 1), 'vect__stop_words': ['about', 'also', 'and', 'because', 'box', 'dish', 'dishes', 'etc', 'front', 'cashier', 'husband', 'immediately', 'just', 'menu', 'minutes', 'others', 'our', 'relay', 'section', 'some', 'that', 'the', 'their', 'them', 'then', 'this', 'very', 'walked', 'was', 'were', 'what', 'when', 'women', 'busy', 'gotta', 'been', 'here', 'times', 'and', 'this', 'the', 'are', 'there', 'options', 'had', 'have', 'you', 'find', 'authentic', 'pretty', 'choose', 'was', 'parking ', 'were', 'plenty', 'pot', 'dishes', 'they', 'serve', 'free', 'low', 'day', 'cuz', 'eat', 'box', 'today', 'give', 'chance', 'something', 'else', 'really', 'short', 'wife', 'plate', 'always', 'second', 'time', 'very', 'came', 'out', 'thier', 'bowl', 'table', 'still', 'bottom', 'sunny', 'all', 'add', 'some', 'your', 'kept', 'almost', 'definitly', 'friend', 'recently', 'stopped', 'arrived', 'packed', 'long', 'plus', 'including', 'cellophane', 'slivers', 'went', 'night', 'staying', 'when', 'home', 'wide', 'now', 'minutes', 'them', 'that', 'other', 'just', 'their', 'range', 'once', 'car', 'drive', 'miles', 'wanted', 'stop', 'along', 'would', 'waiting', 'stay', 'land', 'people', 'brought', 'half', 'dozen', 'mixes', 'each', 'yeas', 'locations', 'found', 'especially', 'significantly', 'plae', 'two', 'blocks', 'away', 'trained', 'places', 'quite', 'can', 'min', 'years', 'started', 'lived', 'countries', 'myself', 'versed', 'twice', 'week', 'owned', 'own', 'currently', 'has', 'sushi', 'order', 'correctly', 'around', 'couple', 'sooo', 'through', 'sister', 'rest', 'being', 'three', 'ordered', 'huge', 'yakimondo', 'say', 'portions', 'large', 'groups', 'lover', 'due', 'neighbor', 'makes', 'most', 'pass', 'only', 'looking', 'word', 'mouth', 'buildingoutside', 'interior', 'where', 'welcome', 'front', 'opted', 'guest', 'another', 'presentation', 'larger', 'show', 'his', 'work', 'done', 'mizo', 'start', 'while', 'did', 'sample', 'till', 'open', 'seats', 'across', 'street', 'which', 'certainly', 'proclaim', 'thought', 'somewhat', 'amount', 'navigating', 'hole', 'wall', 'gets', 'anything', 'also', 'ask', 'how', 'into', 'probably', 'put', 'anyway', 'yesterday', 'honestly', 'whole', 'its', 'speak', 'corner', 'sick', 'ethnic', 'everything', 'coming', 'kitchen', 'things', 'defrosted', 'properly', 'black', 'below', 'average', 'frozen', 'let', 'down', 'definitely', 'extremely', 'what', 'randomly', 'during', 'our', 'managed', 'past', 'location', 'exterior', 'lot', 'alone', 'single', 'piece', 'gimchitold', 'whether', 'ended', 'takeaway', 'aspects', 'dropped', 'accumulated', 'mother', 'law', 'completely', 'aged', 'finding', 'round', 'fooled', 'highly', 'explain', 'those', 'who', 'tourist', 'itself', 'themed', 'decorations', 'seems', 'delicately', 'ranges', 'udon', 'persons', 'sets', 'fix', 'basement', 'any', 'turning', 'reservation', 'literally', 'meters', 'tram', 'station', 'plain', 'view', 'look', 'fact', 'stairs', 'near', 'helping', 'after', 'step', 'realize', 'setting', 'pleasing', 'decor', 'motives', 'modern', 'lines', 'entered', 'certify', 'personal', 'touch', 'noticed', 'high', 'chair', 'return', 'weekend', 'per', 'noticing', 'accommodation', 'book', 'advance', 'evening', 'upon', 'arrival', 'considered', 'ourselves', 'tables', 'predominantly', 'variations', 'boyfriend', 'clear', 'even', 'joked', 'asking', 'prompt', 'center', 'longer', 'morning', 'sight', 'seeing', 'courteous', 'overpaying', 'gave', 'mispronounced', 'thoroughly', 'trio', 'cokes', 'walking', 'dad', 'took', 'mums', 'house', 'might', 'comfort', 'mean', 'isn', 'either', 'reminded', 'higher', 'because', 'prime', 'hours', 'search', 'gem', 'required', 'minute', 'ride', 'see', 'neighborhood', 'part', 'flat', 'city', 'accept', 'carry', 'imagine', 'ready', 'known', 'customer', 'accommodated', 'requests', 'daughter', 'owner', 'patient', 'help', 'split', 'types', 'non', 'pesto', 'beginning', 'choices', 'end', 'saved', 'tongues', 'every', 'pay', 'sized', 'portion', 'background', 'playing', 'person', 'starter', 'mension', 'sayd', 'does', 'locate', 'environment', 'true', 'stated', 'splendid', 'she', 'sorry', 'expecting', 'layers', 'realized', 'redo', 'both', 'leaves', 'slightly', 'broth', 'standards', 'serving', 'recommending', 'prepared', 'presented', 'characteristics', 'personally', 'her', 'meant', 'immediately', 'much', 'chat', 'woman', 'card', 'actually', 'path', 'means', 'dress', 'before', 'line', 'since', 'hair', 'real', 'speaks', 'simple', 'centrally', 'located', 'english', 'issue', 'owners', 'afternoon', 'four', 'warm', 'biggest', 'cozy', 'making', 'meet', 'enter', 'definetly', 'semi', 'gone', 'particularly', 'available', 'walk', 'downside', 'crowns', 'rooms', 'feels', 'totally', 'knew', 'guess', 'advisable', 'ahead', 'incredibly', 'apartment', 'advisor', 'heart', 'warming', 'door', 'notch', 'area', 'somewhere', 'boxes', 'absolutely', 'frequent', 'eater', 'reference', 'material', 'unassuming', 'arrive', 'nonetheless', 'cash', 'earth', 'abroad', 'exquisite', 'reason', 'conditioning', 'ventilation', 'mindblowing', 'mention', 'hold', 'sitting', 'air', 'ground', 'customers', 'days', 'then', 'doing', 'tricky', 'road', 'avarage', 'definately', 'give', 'soon', 'everyday', 'quite', 'get', 'cloths', 'hanger', 'cute', 'hidden', 'part', 'gladly', 'for', 'czk', 'simply', 'starters', 'allowed', 'importantly', 'mom', 'uber', 'ride', 'walk', 'our', 'group', 'comes', 'aunt', 'owns', 'grew', 'hands', 'school', 'absolute', 'having', 'seen', 'steps', 'nothing', 'quiet', 'partner', 'tray', 'etc', 'searching', 'lie', 'finish', 'centre', 'brought', 'everyone', 'older', 'usually', 'increased', 'evenings', 'booking', 'confirm', 'authenticity', 'luck', 'planned', 'customers', 'kinds', 'stuff', 'centrum', 'going', 'smaller', 'shop', 'overall', 'mix', 'already', 'much', 'past', 'month', 'birthday', 'celebration', 'terms', 'delve', 'below', 'wise', 'attentiveness', 'empty', 'occassion', 'revealed', 'amplified', 'nervous', 'guests', 'seated', 'anyone', 'hello', 'mins', 'happening', 'third', 'somehow', 'crowd', 'youngsters', 'winter', 'jacket', 'live', 'nearby', 'substantially', 'improved', 'jap', 'identify', 'blamed', 'favouring', 'provides', 'extreme', 'only', 'pictures', 'study', 'frequently', 'think', 'eum', 'ppong', 'talking', 'tap', 'exactly', 'remembers', 'visiting', 'placed', 'address', 'speaking', 'dull', 'humble', 'surroundings', 'cuz', 'light', 'hospital', 'suchi', 'further', 'relatively', 'skeptical', 'chocked', 'par', 'letdown', 'tad', 'bland', 'dry', 'why', 'prohibitively', 'either', 'washed', 'downplay', 'extensive', 'thing', 'massive', 'rush', 'touched', 'job', 'growing', 'anymore', 'reservations', 'keep', 'offering', 'reading', 'often', 'nonsense', 'number', 'etnic', 'extra', 'assurance', 'decor', 'thus', 'maybe', 'romantic', 'date', 'yourself', 'gentleman', 'rate', 'five', 'perhaps', 'amounts', 'suspicions', 'confirmed', 'sight', 'crystals', 'struggle', 'hungry', 'taxi', 'man', 'knows', 'occasion', 'able', 'booked', 'dined', 'temperature', 'host', 'checked', 'miss', 'four,', 'correct', 'fat', 'stole', 'gentle', 'town', 'plus', 'move', 'stops', 'prepared', 'played', 'pop', 'spice', 'help', 'personnel', 'girlfriend', 'genuinly', 'version', 'doubt', 'occasional', 'tailored', 'given', 'honest', 'aware', 'missed', 'moving', 'expectations', 'key', 'easiest', 'zizkov', 'staircase', 'map', 'eventually', 'passion', 'othet', 'let', 'plates', 'expecting', 'arugula', 'minced', 'manager', 'fifteen', 'complicated', 'ours', 'stayed', 'hotel', 'relation', 'usual', 'unbeatable', 'appears', 'may', 'tonight', 'europe', 'fluent', 'encountered', 'truly', 'accident', 'randomly', 'living', 'obsessed', 'goes', 'cross', 'moved', 'became', 'lazy', 'whatever', 'responsive', 'regard', 'descriptive', 'listings', 'maintaining', 'wooing', 'evr', 'tourism', 'greeted', 'months', 'traveling', 'happened', 'world', 'recipes', 'cure', 'weakness', 'ower', 'warmth', 'afford', 'fuss', 'forward', 'else', 'office', 'week', 'esp', 'item', 'crowns', 'via', 'returned', 'design', 'discover'], 'vect__tokenizer': <function tokenizer_porter at 0x0000026F520BD3A8>}\n",
      "테스트 정확도 : 0.950\n"
     ]
    }
   ],
   "source": [
    "step5_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
